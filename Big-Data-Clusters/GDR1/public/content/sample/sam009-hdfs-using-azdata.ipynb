{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAM009 - HDFS using azdata\n",
    "==========================\n",
    "\n",
    "Description\n",
    "-----------\n",
    "\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "hdfs_folder = \"/tmp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common functions\n",
    "\n",
    "Define helper functions used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Define `run` function for transient fault handling, suggestions on error, and scrolling updates on Windows\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import platform\n",
    "import shlex\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "from subprocess import Popen, PIPE\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def run(cmd, return_output=False, no_output=False, error_hints=[], retry_hints=[], retry_count=0):\n",
    "    \"\"\"\n",
    "    Run shell command, stream stdout, print stderr and optionally return output\n",
    "    \"\"\"\n",
    "    max_retries = 5\n",
    "    install_hint = None\n",
    "    output = \"\"\n",
    "    retry = False\n",
    "\n",
    "    # shlex.split is required on bash and for Windows paths with spaces\n",
    "    #\n",
    "    cmd_actual = shlex.split(cmd)\n",
    "\n",
    "    # When running python, use the python in the ADS sandbox ({sys.executable})\n",
    "    #\n",
    "    if cmd.startswith(\"python \"):\n",
    "        cmd_actual[0] = cmd_actual[0].replace(\"python\", sys.executable)\n",
    "\n",
    "        # On Mac, when ADS is not launched from terminal, LC_ALL may not be set, which causes pip installs to fail\n",
    "        # with:\n",
    "        #\n",
    "        #       UnicodeDecodeError: 'ascii' codec can't decode byte 0xc5 in position 4969: ordinal not in range(128)\n",
    "        #\n",
    "        # Setting it to a default value of \"en_US.UTF-8\" enables pip install to complete\n",
    "        #\n",
    "        if platform.system() == \"Darwin\" and \"LC_ALL\" not in os.environ:\n",
    "            os.environ[\"LC_ALL\"] = \"en_US.UTF-8\"\n",
    "\n",
    "        python_retry_hints, python_error_hints, install_hint = python_hints()\n",
    "        retry_hints += python_retry_hints\n",
    "        error_hints += python_error_hints\n",
    "\n",
    "    if (cmd.startswith(\"kubectl \")):\n",
    "        kubectl_retry_hints, kubectl_error_hints, install_hint = kubectl_hints()\n",
    "        retry_hints += kubectl_retry_hints\n",
    "        error_hints += kubectl_error_hints\n",
    "\n",
    "    if (cmd.startswith(\"azdata \")):\n",
    "        azdata_retry_hints, azdata_error_hints, install_hint = azdata_hints()\n",
    "        retry_hints += azdata_retry_hints\n",
    "        error_hints += azdata_error_hints\n",
    "\n",
    "    # Find the path based location (shutil.which) of the executable that will be run (and display it to aid supportability), this\n",
    "    # seems to be required for .msi installs of azdata.cmd/az.cmd.  (otherwise Popen returns FileNotFound) \n",
    "    #\n",
    "    # NOTE: Bash needs cmd to be the list of the space separated values hence shlex.split.\n",
    "    #\n",
    "    which_binary = shutil.which(cmd_actual[0])\n",
    "\n",
    "    if which_binary == None:\n",
    "        if install_hint is not None:\n",
    "            display(Markdown(f'SUGGEST: Use {install_hint} to resolve this issue.'))\n",
    "\n",
    "        raise FileNotFoundError(f\"Executable '{cmd_actual[0]}' not found in path (where/which)\")\n",
    "    else:   \n",
    "        cmd_actual[0] = which_binary\n",
    "\n",
    "    start_time = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "    print(f\"START: {cmd} @ {start_time} ({datetime.datetime.utcnow().replace(microsecond=0)} UTC)\")\n",
    "    print(f\"       using: {which_binary} ({platform.system()} {platform.release()} on {platform.machine()})\")\n",
    "    print(f\"       cwd: {os.getcwd()}\")\n",
    "\n",
    "    # Command-line tools such as CURL and AZDATA HDFS commands output\n",
    "    # scrolling progress bars, which causes Jupyter to hang forever, to\n",
    "    # workaround this, use no_output=True\n",
    "    #\n",
    "    try:\n",
    "        if no_output:\n",
    "            p = Popen(cmd_actual)\n",
    "        else:\n",
    "            p = Popen(cmd_actual, stdout=PIPE, stderr=PIPE, bufsize=1)\n",
    "            with p.stdout:\n",
    "                for line in iter(p.stdout.readline, b''):\n",
    "                    line = line.decode()\n",
    "                    if return_output:\n",
    "                        output = output + line\n",
    "                    else:\n",
    "                        if cmd.startswith(\"azdata notebook run\"): # Hyperlink the .ipynb file\n",
    "                            regex = re.compile('  \"(.*)\"\\: \"(.*)\"') \n",
    "                            match = regex.match(line)\n",
    "                            if match:\n",
    "                                if match.group(1).find(\"HTML\") != -1:\n",
    "                                    display(Markdown(f' - \"{match.group(1)}\": \"{match.group(2)}\"'))\n",
    "                                else:\n",
    "                                    display(Markdown(f' - \"{match.group(1)}\": \"[{match.group(2)}]({match.group(2)})\"'))\n",
    "                        else:\n",
    "                            print(line, end='')\n",
    "        p.wait()\n",
    "    except FileNotFoundError as e:\n",
    "        if install_hint is not None:\n",
    "            display(Markdown(f'SUGGEST: Use {install_hint} to resolve this issue.'))\n",
    "\n",
    "        raise FileNotFoundError(f\"Executable '{cmd_actual[0]}' not found in path (where/which)\") from e\n",
    "\n",
    "    if not no_output:\n",
    "        for line in iter(p.stderr.readline, b''):\n",
    "            line_decoded = line.decode()\n",
    "\n",
    "            # azdata emits a single empty line to stderr when doing an hdfs cp, don't\n",
    "            # print this empty \"ERR:\" as it confuses.\n",
    "            #\n",
    "            if line_decoded == \"\":\n",
    "                continue\n",
    "            \n",
    "            print(f\"ERR: {line_decoded}\", end='')\n",
    "\n",
    "            for error_hint in error_hints:\n",
    "                if line_decoded.find(error_hint[0]) != -1:\n",
    "                    display(Markdown(f'SUGGEST: Use [{error_hint[2]}]({error_hint[1]}) to resolve this issue.'))\n",
    "\n",
    "            for retry_hint in retry_hints:\n",
    "                if line_decoded.find(retry_hint) != -1:\n",
    "                    if retry_count < max_retries:\n",
    "                        print(f\"RETRY: {retry_count} (due to: {retry_hint})\")\n",
    "                        retry_count = retry_count + 1\n",
    "                        output = run(cmd, return_output=return_output, error_hints=error_hints, retry_hints=retry_hints, retry_count=retry_count)\n",
    "\n",
    "                        if return_output:\n",
    "                            return output\n",
    "                        else:\n",
    "                            return\n",
    "\n",
    "    elapsed = datetime.datetime.now().replace(microsecond=0) - start_time\n",
    "\n",
    "    if p.returncode != 0:\n",
    "        raise SystemExit(f'Shell command:\\n\\n\\t{cmd} ({elapsed}s elapsed)\\n\\nreturned non-zero exit code: {str(p.returncode)}.\\n')\n",
    "\n",
    "    print(f'\\nSUCCESS: {elapsed}s elapsed\\n')\n",
    "\n",
    "    if return_output:\n",
    "        return output\n",
    "\n",
    "def kubectl_hints():\n",
    "\n",
    "    retry_hints = [\n",
    "        \"A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\"\n",
    "    ]\n",
    "\n",
    "    error_hints = [\n",
    "    [\"\"\"no such host\"\"\", \"\"\"../monitor-k8s/tsg010-get-kubernetes-contexts.ipynb\"\"\", \"\"\"TSG010 - Get configuration contexts\"\"\"],\n",
    "    [\"\"\"no such host\"\"\", \"\"\"../repair/tsg011-restart-sparkhistory-server.ipynb\"\"\", \"\"\"TSG011 - Restart sparkhistory server\"\"\"],\n",
    "    [\"\"\"No connection could be made because the target machine actively refused it\"\"\", \"\"\"../repair/tsg056-kubectl-no-connection-could-be-made.ipynb\"\"\", \"\"\"TSG056 - Kubectl fails with No connection could be made because the target machine actively refused it\"\"\"]\n",
    "]\n",
    "\n",
    "    install_hint = \"[SOP036 - Install kubectl command line interface](../install/sop036-install-kubectl.ipynb)'\"\n",
    "\n",
    "    return retry_hints, error_hints, install_hint\n",
    "\n",
    "\n",
    "def azdata_hints():\n",
    "\n",
    "    retry_hints = [\n",
    "        \"Endpoint sql-server-master does not exist\",\n",
    "        \"Endpoint livy does not exist\",\n",
    "        \"Failed to get state for cluster\",\n",
    "        \"Endpoint webhdfs does not exist\",\n",
    "        \"Adaptive Server is unavailable or does not exist\",\n",
    "        \"Error: Address already in use\",\n",
    "        \"Timed out getting health status after 5000 milliseconds\"\n",
    "    ]\n",
    "\n",
    "    error_hints = [\n",
    "    [\"\"\"azdata login\"\"\", \"\"\"../common/sop028-azdata-login.ipynb\"\"\", \"\"\"SOP028 - azdata login\"\"\"],\n",
    "    [\"\"\"The token is expired\"\"\", \"\"\"../common/sop028-azdata-login.ipynb\"\"\", \"\"\"SOP028 - azdata login\"\"\"],\n",
    "    [\"\"\"Reason: Unauthorized\"\"\", \"\"\"../common/sop028-azdata-login.ipynb\"\"\", \"\"\"SOP028 - azdata login\"\"\"],\n",
    "    [\"\"\"Max retries exceeded with url: /api/v1/bdc/endpoints\"\"\", \"\"\"../common/sop028-azdata-login.ipynb\"\"\", \"\"\"SOP028 - azdata login\"\"\"],\n",
    "    [\"\"\"Look at the controller logs for more details\"\"\", \"\"\"../diagnose/tsg027-observe-bdc-create.ipynb\"\"\", \"\"\"TSG027 - Observe cluster deployment\"\"\"],\n",
    "    [\"\"\"provided port is already allocated\"\"\", \"\"\"../log-files/tsg062-tail-bdc-previous-container-logs.ipynb\"\"\", \"\"\"TSG062 - Get tail of all previous container logs for pods in BDC namespace\"\"\"],\n",
    "    [\"\"\"Create cluster failed since the existing namespace\"\"\", \"\"\"../install/sop061-delete-bdc.ipynb\"\"\", \"\"\"SOP061 - Delete a big data cluster\"\"\"],\n",
    "    [\"\"\"Failed to complete kube config setup\"\"\", \"\"\"../repair/tsg067-failed-to-complete-kube-config-setup.ipynb\"\"\", \"\"\"TSG067 - Failed to complete kube config setup\"\"\"],\n",
    "    [\"\"\"Error processing command: \"ApiError\"\"\", \"\"\"../repair/tsg110-azdata-returns-apierror.ipynb\"\"\", \"\"\"TSG110 - Azdata returns ApiError\"\"\"],\n",
    "    [\"\"\"Error processing command: \"ControllerError\"\"\", \"\"\"../log-analyzers/tsg036-get-controller-logs.ipynb\"\"\", \"\"\"TSG036 - Controller logs\"\"\"],\n",
    "    [\"\"\"ERROR: 500\"\"\", \"\"\"../log-analyzers/tsg046-get-knox-logs.ipynb\"\"\", \"\"\"TSG046 - Knox gateway logs\"\"\"],\n",
    "    [\"\"\"Data source name not found and no default driver specified\"\"\", \"\"\"../install/sop069-install-odbc-driver-for-sql-server.ipynb\"\"\", \"\"\"SOP069 - Install ODBC for SQL Server\"\"\"],\n",
    "    [\"\"\"Can't open lib 'ODBC Driver 17 for SQL Server\"\"\", \"\"\"../install/sop069-install-odbc-driver-for-sql-server.ipynb\"\"\", \"\"\"SOP069 - Install ODBC for SQL Server\"\"\"]\n",
    "]\n",
    "\n",
    "    install_hint = \"[SOP055 - Install azdata command line interface](../install/sop055-install-azdata.ipynb)'\"\n",
    "\n",
    "    return retry_hints, error_hints, install_hint\n",
    "\n",
    "print('Common functions defined successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Kubernetes namespace for the big data cluster\n",
    "\n",
    "Get the namespace of the big data cluster use the kubectl command line\n",
    "interface .\n",
    "\n",
    "NOTE: If there is more than one big data cluster in the target\n",
    "Kubernetes cluster, then set \\[0\\] to the correct value for the big data\n",
    "cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Place Kubernetes namespace name for BDC into 'namespace' variable\n",
    "\n",
    "try:\n",
    "    namespace = run(f'kubectl get namespace --selector=MSSQL_CLUSTER -o jsonpath={{.items[0].metadata.name}}', return_output=True)\n",
    "except:\n",
    "    from IPython.display import Markdown\n",
    "    print(f\"ERROR: Unable to find a Kubernetes namespace with label 'MSSQL_CLUSTER'.  SQL Server Big Data Cluster Kubernetes namespaces contain the lavel 'MSSQL_CLUSTER'.\")\n",
    "    display(Markdown(f'SUGGEST: Use [TSG081 - Get namespaces (Kubernetes)](../monitor-k8s/tsg081-get-kubernetes-namespaces.ipynb) to resolve this issue.'))\n",
    "    display(Markdown(f'SUGGEST: Use [TSG010 - Get configuration contexts](../monitor-k8s/tsg010-get-kubernetes-contexts.ipynb) to resolve this issue.'))\n",
    "    display(Markdown(f'SUGGEST: Use [SOP011 - Set kubernetes configuration context](../common/sop011-set-kubernetes-context.ipynb) to resolve this issue.'))\n",
    "    raise\n",
    "else:\n",
    "    print(f'The SQL Server Big Data Cluster Kubernetes namespace is: {namespace}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the controller username and password\n",
    "\n",
    "Get the controller username and password from the Kubernetes Secret\n",
    "Store and place in the required AZDATA\\_USERNAME and AZDATA\\_PASSWORD\n",
    "environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Place controller secret in AZDATA_USERNAME/AZDATA_PASSWORD environment variables\n",
    "\n",
    "import os, base64\n",
    "\n",
    "os.environ[\"AZDATA_USERNAME\"] = run(f'kubectl get secret/controller-login-secret -n {namespace} -o jsonpath={{.data.username}}', return_output=True)\n",
    "os.environ[\"AZDATA_USERNAME\"] = base64.b64decode(os.environ[\"AZDATA_USERNAME\"]).decode('utf-8')\n",
    "\n",
    "os.environ[\"AZDATA_PASSWORD\"] = run(f'kubectl get secret/controller-login-secret -n {namespace} -o jsonpath={{.data.password}}', return_output=True)\n",
    "os.environ[\"AZDATA_PASSWORD\"] = base64.b64decode(os.environ[\"AZDATA_PASSWORD\"]).decode('utf-8')\n",
    "\n",
    "\n",
    "print(f\"Controller username '{os.environ['AZDATA_USERNAME']}' and password stored in environment variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a 10MB file to copy to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "f = open('file-10MB',\"wb\")\n",
    "f.seek((1024 * 1024 * 10) -1)\n",
    "f.write(b\"\\0\")\n",
    "f.close()\n",
    "\n",
    "os.stat(\"file-10MB\").st_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up any files from a previous incomplete run of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(f\"azdata bdc hdfs rmr --path {hdfs_folder}/sam009-hdfs-using-azdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.isfile(\"file-10MB.copied\"):\n",
    "    os.remove(\"file-10MB.copied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy file from local filesystem to remote HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "time = strftime(\"%H-%M-%S\", gmtime())\n",
    "\n",
    "run(f\"azdata bdc hdfs cp --from-path file-10MB --to-path hdfs:{hdfs_folder}/sam009-hdfs-using-azdata/file-10MB-\" + time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy file from remote HDFS to local filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(f\"azdata bdc hdfs cp --from-path hdfs:{hdfs_folder}/sam009-hdfs-using-azdata/file-10MB-\" + time + \" --to-path ./file-10MB.copied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check before and after file size\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_file_size = os.path.getsize(\"file-10MB\")\n",
    "after_file_size =  os.path.getsize(\"file-10MB.copied\")\n",
    "\n",
    "if before_file_size != after_file_size:\n",
    "    raise SystemExit(f\"File sizes are different, before {before_file_size}, after {after_file_size}\")\n",
    "else:\n",
    "    print(\"SUCCESS: Copy was successful, file sizes are the same\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up files in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(f\"azdata bdc hdfs rm --path {hdfs_folder}/sam009-hdfs-using-azdata/file-10MB-\" + time)\n",
    "run(f\"azdata bdc hdfs rm --path {hdfs_folder}/sam009-hdfs-using-azdata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up file on local filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.remove(\"file-10MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Notebook execution complete.')"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "azdata": {
   "test": {
    "strategy": "Parallel",
    "ci": true,
    "gci": false
   },
   "sideaffects": false
  }
 }
}

